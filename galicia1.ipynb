{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['device_data.csv', 'PAGE.csv', 'CONTENT_CATEGORY.csv', 'conversiones.csv', 'sampleSubmission.csv', 'pageviews_complemento.csv', 'SITE_ID.csv', 'CONTENT_CATEGORY_BOTTOM.csv', 'CONTENT_CATEGORY_TOP.csv', 'README.md', 'pageviews.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "np.set_printoptions(threshold=20)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([\n",
    "       pd.read_csv(\"./data/pageviews.csv\", parse_dates=[\"FEC_EVENT\"]),\n",
    "       pd.read_csv(\"./data/pageviews_complemento.csv\", parse_dates=[\"FEC_EVENT\"])\n",
    "], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEC_EVENT</th>\n",
       "      <th>PAGE</th>\n",
       "      <th>CONTENT_CATEGORY</th>\n",
       "      <th>CONTENT_CATEGORY_TOP</th>\n",
       "      <th>CONTENT_CATEGORY_BOTTOM</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>ON_SITE_SEARCH_TERM</th>\n",
       "      <th>USER_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-30 07:35:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-30 07:35:52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-30 07:36:11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-30 07:36:16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-30 07:41:38</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FEC_EVENT  PAGE  CONTENT_CATEGORY  CONTENT_CATEGORY_TOP  \\\n",
       "0 2018-03-30 07:35:48     1                 1                     1   \n",
       "1 2018-03-30 07:35:52     2                 2                     2   \n",
       "2 2018-03-30 07:36:11     3                 2                     2   \n",
       "3 2018-03-30 07:36:16     4                 2                     2   \n",
       "4 2018-03-30 07:41:38     5                 2                     2   \n",
       "\n",
       "   CONTENT_CATEGORY_BOTTOM  SITE_ID  ON_SITE_SEARCH_TERM  USER_ID  \n",
       "0                        1        1                    1        0  \n",
       "1                        2        2                    1        0  \n",
       "2                        2        3                    1        0  \n",
       "3                        2        3                    1        0  \n",
       "4                        2        2                    1        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo PAGE\n",
      "haciendo CONTENT_CATEGORY\n",
      "haciendo CONTENT_CATEGORY_TOP\n",
      "haciendo CONTENT_CATEGORY_BOTTOM\n",
      "haciendo SITE_ID\n",
      "haciendo ON_SITE_SEARCH_TERM\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_test.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_test = pd.concat(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAGE_1</th>\n",
       "      <th>PAGE_2</th>\n",
       "      <th>PAGE_3</th>\n",
       "      <th>PAGE_4</th>\n",
       "      <th>PAGE_5</th>\n",
       "      <th>PAGE_6</th>\n",
       "      <th>PAGE_7</th>\n",
       "      <th>PAGE_8</th>\n",
       "      <th>PAGE_9</th>\n",
       "      <th>PAGE_10</th>\n",
       "      <th>...</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_285</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_286</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_287</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_288</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_289</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_290</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_291</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_292</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_293</th>\n",
       "      <th>ON_SITE_SEARCH_TERM_295</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USER_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.128440</td>\n",
       "      <td>0.064842</td>\n",
       "      <td>0.043384</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.044472</td>\n",
       "      <td>0.114601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103742</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054950</td>\n",
       "      <td>0.128375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032517</td>\n",
       "      <td>0.168074</td>\n",
       "      <td>0.114443</td>\n",
       "      <td>0.025760</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.059966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.192765</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>0.034625</td>\n",
       "      <td>0.040827</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.120451</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.046699</td>\n",
       "      <td>0.018035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.176490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PAGE_1    PAGE_2    PAGE_3    PAGE_4    PAGE_5    PAGE_6    PAGE_7  \\\n",
       "USER_ID                                                                         \n",
       "0        0.028300  0.128440  0.064842  0.043384  0.016949  0.005287  0.000155   \n",
       "1        0.103742  0.157271  0.065846  0.013738  0.006158  0.003316  0.000000   \n",
       "2        0.032517  0.168074  0.114443  0.025760  0.026605  0.002956  0.000000   \n",
       "3        0.005168  0.192765  0.145736  0.034625  0.040827  0.012920  0.000000   \n",
       "4        0.010628  0.120451  0.099839  0.008696  0.046699  0.018035  0.000000   \n",
       "\n",
       "           PAGE_8    PAGE_9   PAGE_10  ...  ON_SITE_SEARCH_TERM_285  \\\n",
       "USER_ID                                ...                            \n",
       "0        0.000155  0.044472  0.114601  ...                      0.0   \n",
       "1        0.000000  0.054950  0.128375  ...                      0.0   \n",
       "2        0.000422  0.027872  0.059966  ...                      0.0   \n",
       "3        0.000000  0.000000  0.000000  ...                      0.0   \n",
       "4        0.000322  0.000966  0.176490  ...                      0.0   \n",
       "\n",
       "         ON_SITE_SEARCH_TERM_286  ON_SITE_SEARCH_TERM_287  \\\n",
       "USER_ID                                                     \n",
       "0                            0.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "\n",
       "         ON_SITE_SEARCH_TERM_288  ON_SITE_SEARCH_TERM_289  \\\n",
       "USER_ID                                                     \n",
       "0                            0.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "\n",
       "         ON_SITE_SEARCH_TERM_290  ON_SITE_SEARCH_TERM_291  \\\n",
       "USER_ID                                                     \n",
       "0                            0.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "\n",
       "         ON_SITE_SEARCH_TERM_292  ON_SITE_SEARCH_TERM_293  \\\n",
       "USER_ID                                                     \n",
       "0                            0.0                      0.0   \n",
       "1                            0.0                      0.0   \n",
       "2                            0.0                      0.0   \n",
       "3                            0.0                      0.0   \n",
       "4                            0.0                      0.0   \n",
       "\n",
       "         ON_SITE_SEARCH_TERM_295  \n",
       "USER_ID                           \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "\n",
       "[5 rows x 2174 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11676, 2174)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586378479241177"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0,0:65].sum() # la suma de las frecuencias debe ser 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo PAGE\n",
      "haciendo CONTENT_CATEGORY\n",
      "haciendo CONTENT_CATEGORY_TOP\n",
      "haciendo CONTENT_CATEGORY_BOTTOM\n",
      "haciendo SITE_ID\n",
      "haciendo ON_SITE_SEARCH_TERM\n"
     ]
    }
   ],
   "source": [
    "data = data[data.FEC_EVENT.dt.month < 10]\n",
    "X_train = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_train.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_train = pd.concat(X_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USER_ID\n",
       "0        0.001221\n",
       "1        0.001224\n",
       "2        0.005242\n",
       "3        0.007722\n",
       "4        0.020178\n",
       "           ...   \n",
       "11671    0.034161\n",
       "11672    0.000000\n",
       "11673    0.016129\n",
       "11674    0.000000\n",
       "11675    0.000000\n",
       "Name: PAGE_57, Length: 11529, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9723127035830619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0,0:65].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(X_train.columns).intersection(set(X_test.columns)))\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev = pd.read_csv(\"./data/conversiones.csv\")\n",
    "y_train = pd.Series(0, index=X_train.index)\n",
    "idx = set(y_prev[y_prev.mes >= 10].USER_ID.unique()).intersection(set(X_train.index))\n",
    "y_train.loc[list(idx)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11529, 2026) (11676, 2026)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.84463\ttraining's binary_logloss: 0.130831\tvalid_1's auc: 0.7824\tvalid_1's binary_logloss: 0.124401\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.878782\ttraining's binary_logloss: 0.119809\tvalid_1's auc: 0.791437\tvalid_1's binary_logloss: 0.120441\n",
      "[3]\ttraining's auc: 0.901236\ttraining's binary_logloss: 0.112169\tvalid_1's auc: 0.819521\tvalid_1's binary_logloss: 0.117693\n",
      "[4]\ttraining's auc: 0.919962\ttraining's binary_logloss: 0.105794\tvalid_1's auc: 0.827854\tvalid_1's binary_logloss: 0.115981\n",
      "[5]\ttraining's auc: 0.924375\ttraining's binary_logloss: 0.10075\tvalid_1's auc: 0.836485\tvalid_1's binary_logloss: 0.11377\n",
      "[6]\ttraining's auc: 0.927593\ttraining's binary_logloss: 0.0960927\tvalid_1's auc: 0.840354\tvalid_1's binary_logloss: 0.112043\n",
      "[7]\ttraining's auc: 0.941066\ttraining's binary_logloss: 0.0918713\tvalid_1's auc: 0.84582\tvalid_1's binary_logloss: 0.111091\n",
      "[8]\ttraining's auc: 0.946036\ttraining's binary_logloss: 0.0880221\tvalid_1's auc: 0.845225\tvalid_1's binary_logloss: 0.110431\n",
      "[9]\ttraining's auc: 0.954161\ttraining's binary_logloss: 0.0843587\tvalid_1's auc: 0.841883\tvalid_1's binary_logloss: 0.110237\n",
      "[10]\ttraining's auc: 0.960257\ttraining's binary_logloss: 0.0811973\tvalid_1's auc: 0.84283\tvalid_1's binary_logloss: 0.109284\n",
      "[11]\ttraining's auc: 0.962281\ttraining's binary_logloss: 0.0782885\tvalid_1's auc: 0.843398\tvalid_1's binary_logloss: 0.108409\n",
      "[12]\ttraining's auc: 0.965839\ttraining's binary_logloss: 0.0755536\tvalid_1's auc: 0.842275\tvalid_1's binary_logloss: 0.108138\n",
      "[13]\ttraining's auc: 0.970303\ttraining's binary_logloss: 0.0728996\tvalid_1's auc: 0.842465\tvalid_1's binary_logloss: 0.107808\n",
      "[14]\ttraining's auc: 0.972212\ttraining's binary_logloss: 0.0703288\tvalid_1's auc: 0.842343\tvalid_1's binary_logloss: 0.107493\n",
      "[15]\ttraining's auc: 0.977284\ttraining's binary_logloss: 0.0680711\tvalid_1's auc: 0.842018\tvalid_1's binary_logloss: 0.107202\n",
      "[16]\ttraining's auc: 0.978191\ttraining's binary_logloss: 0.0660739\tvalid_1's auc: 0.838231\tvalid_1's binary_logloss: 0.107786\n",
      "[17]\ttraining's auc: 0.979325\ttraining's binary_logloss: 0.0640164\tvalid_1's auc: 0.839746\tvalid_1's binary_logloss: 0.107282\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.941066\ttraining's binary_logloss: 0.0918713\tvalid_1's auc: 0.84582\tvalid_1's binary_logloss: 0.111091\n",
      "[1]\ttraining's auc: 0.847314\ttraining's binary_logloss: 0.129187\tvalid_1's auc: 0.79435\tvalid_1's binary_logloss: 0.147758\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.887017\ttraining's binary_logloss: 0.117826\tvalid_1's auc: 0.802202\tvalid_1's binary_logloss: 0.145673\n",
      "[3]\ttraining's auc: 0.907871\ttraining's binary_logloss: 0.109965\tvalid_1's auc: 0.816229\tvalid_1's binary_logloss: 0.141802\n",
      "[4]\ttraining's auc: 0.919421\ttraining's binary_logloss: 0.103895\tvalid_1's auc: 0.815669\tvalid_1's binary_logloss: 0.140013\n",
      "[5]\ttraining's auc: 0.923983\ttraining's binary_logloss: 0.0983534\tvalid_1's auc: 0.812599\tvalid_1's binary_logloss: 0.13909\n",
      "[6]\ttraining's auc: 0.929741\ttraining's binary_logloss: 0.0936627\tvalid_1's auc: 0.816525\tvalid_1's binary_logloss: 0.137287\n",
      "[7]\ttraining's auc: 0.940055\ttraining's binary_logloss: 0.0895374\tvalid_1's auc: 0.814704\tvalid_1's binary_logloss: 0.135781\n",
      "[8]\ttraining's auc: 0.947606\ttraining's binary_logloss: 0.0861772\tvalid_1's auc: 0.811294\tvalid_1's binary_logloss: 0.135515\n",
      "[9]\ttraining's auc: 0.952912\ttraining's binary_logloss: 0.082453\tvalid_1's auc: 0.809232\tvalid_1's binary_logloss: 0.134728\n",
      "[10]\ttraining's auc: 0.960926\ttraining's binary_logloss: 0.0793394\tvalid_1's auc: 0.820407\tvalid_1's binary_logloss: 0.134077\n",
      "[11]\ttraining's auc: 0.965411\ttraining's binary_logloss: 0.0763895\tvalid_1's auc: 0.816964\tvalid_1's binary_logloss: 0.134411\n",
      "[12]\ttraining's auc: 0.969742\ttraining's binary_logloss: 0.0737705\tvalid_1's auc: 0.816667\tvalid_1's binary_logloss: 0.133664\n",
      "[13]\ttraining's auc: 0.970697\ttraining's binary_logloss: 0.0713286\tvalid_1's auc: 0.814814\tvalid_1's binary_logloss: 0.134072\n",
      "[14]\ttraining's auc: 0.974266\ttraining's binary_logloss: 0.0689801\tvalid_1's auc: 0.816558\tvalid_1's binary_logloss: 0.133657\n",
      "[15]\ttraining's auc: 0.980556\ttraining's binary_logloss: 0.0664751\tvalid_1's auc: 0.822579\tvalid_1's binary_logloss: 0.133561\n",
      "[16]\ttraining's auc: 0.982209\ttraining's binary_logloss: 0.064341\tvalid_1's auc: 0.810175\tvalid_1's binary_logloss: 0.133372\n",
      "[17]\ttraining's auc: 0.986414\ttraining's binary_logloss: 0.0624917\tvalid_1's auc: 0.80864\tvalid_1's binary_logloss: 0.133382\n",
      "[18]\ttraining's auc: 0.988732\ttraining's binary_logloss: 0.0606934\tvalid_1's auc: 0.825079\tvalid_1's binary_logloss: 0.133014\n",
      "[19]\ttraining's auc: 0.991453\ttraining's binary_logloss: 0.0587968\tvalid_1's auc: 0.823763\tvalid_1's binary_logloss: 0.133221\n",
      "[20]\ttraining's auc: 0.99326\ttraining's binary_logloss: 0.0571951\tvalid_1's auc: 0.826176\tvalid_1's binary_logloss: 0.13265\n",
      "[21]\ttraining's auc: 0.994387\ttraining's binary_logloss: 0.0554248\tvalid_1's auc: 0.824629\tvalid_1's binary_logloss: 0.133024\n",
      "[22]\ttraining's auc: 0.995195\ttraining's binary_logloss: 0.053911\tvalid_1's auc: 0.821449\tvalid_1's binary_logloss: 0.133193\n",
      "[23]\ttraining's auc: 0.996515\ttraining's binary_logloss: 0.052416\tvalid_1's auc: 0.818258\tvalid_1's binary_logloss: 0.133269\n",
      "[24]\ttraining's auc: 0.997261\ttraining's binary_logloss: 0.0509458\tvalid_1's auc: 0.817073\tvalid_1's binary_logloss: 0.133865\n",
      "[25]\ttraining's auc: 0.99815\ttraining's binary_logloss: 0.0495437\tvalid_1's auc: 0.824092\tvalid_1's binary_logloss: 0.132966\n",
      "[26]\ttraining's auc: 0.998532\ttraining's binary_logloss: 0.0482848\tvalid_1's auc: 0.823653\tvalid_1's binary_logloss: 0.132848\n",
      "[27]\ttraining's auc: 0.998848\ttraining's binary_logloss: 0.047047\tvalid_1's auc: 0.825605\tvalid_1's binary_logloss: 0.132997\n",
      "[28]\ttraining's auc: 0.999045\ttraining's binary_logloss: 0.0457117\tvalid_1's auc: 0.824816\tvalid_1's binary_logloss: 0.132974\n",
      "[29]\ttraining's auc: 0.9993\ttraining's binary_logloss: 0.0445176\tvalid_1's auc: 0.823807\tvalid_1's binary_logloss: 0.133252\n",
      "[30]\ttraining's auc: 0.999439\ttraining's binary_logloss: 0.043392\tvalid_1's auc: 0.823609\tvalid_1's binary_logloss: 0.133345\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.99326\ttraining's binary_logloss: 0.0571951\tvalid_1's auc: 0.826176\tvalid_1's binary_logloss: 0.13265\n",
      "[1]\ttraining's auc: 0.842972\ttraining's binary_logloss: 0.127937\tvalid_1's auc: 0.740924\tvalid_1's binary_logloss: 0.149768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.884609\ttraining's binary_logloss: 0.117142\tvalid_1's auc: 0.782425\tvalid_1's binary_logloss: 0.145436\n",
      "[3]\ttraining's auc: 0.907953\ttraining's binary_logloss: 0.109558\tvalid_1's auc: 0.789325\tvalid_1's binary_logloss: 0.143413\n",
      "[4]\ttraining's auc: 0.914685\ttraining's binary_logloss: 0.103311\tvalid_1's auc: 0.784536\tvalid_1's binary_logloss: 0.142168\n",
      "[5]\ttraining's auc: 0.92259\ttraining's binary_logloss: 0.0984127\tvalid_1's auc: 0.780067\tvalid_1's binary_logloss: 0.142224\n",
      "[6]\ttraining's auc: 0.932136\ttraining's binary_logloss: 0.0936055\tvalid_1's auc: 0.774195\tvalid_1's binary_logloss: 0.141507\n",
      "[7]\ttraining's auc: 0.944024\ttraining's binary_logloss: 0.08944\tvalid_1's auc: 0.793151\tvalid_1's binary_logloss: 0.139115\n",
      "[8]\ttraining's auc: 0.952117\ttraining's binary_logloss: 0.0857487\tvalid_1's auc: 0.792519\tvalid_1's binary_logloss: 0.138233\n",
      "[9]\ttraining's auc: 0.964084\ttraining's binary_logloss: 0.0819114\tvalid_1's auc: 0.807241\tvalid_1's binary_logloss: 0.136076\n",
      "[10]\ttraining's auc: 0.966189\ttraining's binary_logloss: 0.0789224\tvalid_1's auc: 0.815385\tvalid_1's binary_logloss: 0.134398\n",
      "[11]\ttraining's auc: 0.967215\ttraining's binary_logloss: 0.0759298\tvalid_1's auc: 0.819971\tvalid_1's binary_logloss: 0.133412\n",
      "[12]\ttraining's auc: 0.972179\ttraining's binary_logloss: 0.0733483\tvalid_1's auc: 0.815932\tvalid_1's binary_logloss: 0.13347\n",
      "[13]\ttraining's auc: 0.974791\ttraining's binary_logloss: 0.0708197\tvalid_1's auc: 0.814624\tvalid_1's binary_logloss: 0.133392\n",
      "[14]\ttraining's auc: 0.977542\ttraining's binary_logloss: 0.0685801\tvalid_1's auc: 0.819843\tvalid_1's binary_logloss: 0.133334\n",
      "[15]\ttraining's auc: 0.980528\ttraining's binary_logloss: 0.0662678\tvalid_1's auc: 0.819789\tvalid_1's binary_logloss: 0.132485\n",
      "[16]\ttraining's auc: 0.986161\ttraining's binary_logloss: 0.0639149\tvalid_1's auc: 0.816757\tvalid_1's binary_logloss: 0.132639\n",
      "[17]\ttraining's auc: 0.987045\ttraining's binary_logloss: 0.0620818\tvalid_1's auc: 0.815192\tvalid_1's binary_logloss: 0.132607\n",
      "[18]\ttraining's auc: 0.988703\ttraining's binary_logloss: 0.0601377\tvalid_1's auc: 0.814131\tvalid_1's binary_logloss: 0.132792\n",
      "[19]\ttraining's auc: 0.990618\ttraining's binary_logloss: 0.0584389\tvalid_1's auc: 0.811367\tvalid_1's binary_logloss: 0.132862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's auc: 0.992676\ttraining's binary_logloss: 0.0566967\tvalid_1's auc: 0.809084\tvalid_1's binary_logloss: 0.133031\n",
      "[21]\ttraining's auc: 0.995659\ttraining's binary_logloss: 0.0548915\tvalid_1's auc: 0.806524\tvalid_1's binary_logloss: 0.133341\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's auc: 0.967215\ttraining's binary_logloss: 0.0759298\tvalid_1's auc: 0.819971\tvalid_1's binary_logloss: 0.133412\n",
      "[1]\ttraining's auc: 0.832379\ttraining's binary_logloss: 0.130568\tvalid_1's auc: 0.781191\tvalid_1's binary_logloss: 0.129972\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.88351\ttraining's binary_logloss: 0.120673\tvalid_1's auc: 0.816126\tvalid_1's binary_logloss: 0.12789\n",
      "[3]\ttraining's auc: 0.905186\ttraining's binary_logloss: 0.113402\tvalid_1's auc: 0.83082\tvalid_1's binary_logloss: 0.125021\n",
      "[4]\ttraining's auc: 0.913101\ttraining's binary_logloss: 0.10693\tvalid_1's auc: 0.83114\tvalid_1's binary_logloss: 0.122956\n",
      "[5]\ttraining's auc: 0.920572\ttraining's binary_logloss: 0.10107\tvalid_1's auc: 0.838232\tvalid_1's binary_logloss: 0.120782\n",
      "[6]\ttraining's auc: 0.932523\ttraining's binary_logloss: 0.0962733\tvalid_1's auc: 0.828597\tvalid_1's binary_logloss: 0.118727\n",
      "[7]\ttraining's auc: 0.937081\ttraining's binary_logloss: 0.0922487\tvalid_1's auc: 0.833401\tvalid_1's binary_logloss: 0.116831\n",
      "[8]\ttraining's auc: 0.948664\ttraining's binary_logloss: 0.0885702\tvalid_1's auc: 0.847291\tvalid_1's binary_logloss: 0.116238\n",
      "[9]\ttraining's auc: 0.958104\ttraining's binary_logloss: 0.0847531\tvalid_1's auc: 0.845707\tvalid_1's binary_logloss: 0.115448\n",
      "[10]\ttraining's auc: 0.963205\ttraining's binary_logloss: 0.0815694\tvalid_1's auc: 0.84655\tvalid_1's binary_logloss: 0.114041\n",
      "[11]\ttraining's auc: 0.965487\ttraining's binary_logloss: 0.0787287\tvalid_1's auc: 0.83818\tvalid_1's binary_logloss: 0.113446\n",
      "[12]\ttraining's auc: 0.967306\ttraining's binary_logloss: 0.0760228\tvalid_1's auc: 0.835817\tvalid_1's binary_logloss: 0.11326\n",
      "[13]\ttraining's auc: 0.96963\ttraining's binary_logloss: 0.0735091\tvalid_1's auc: 0.835114\tvalid_1's binary_logloss: 0.113022\n",
      "[14]\ttraining's auc: 0.973809\ttraining's binary_logloss: 0.0711394\tvalid_1's auc: 0.835446\tvalid_1's binary_logloss: 0.112698\n",
      "[15]\ttraining's auc: 0.976838\ttraining's binary_logloss: 0.0688346\tvalid_1's auc: 0.838781\tvalid_1's binary_logloss: 0.111662\n",
      "[16]\ttraining's auc: 0.979228\ttraining's binary_logloss: 0.0668027\tvalid_1's auc: 0.842346\tvalid_1's binary_logloss: 0.110904\n",
      "[17]\ttraining's auc: 0.980378\ttraining's binary_logloss: 0.0648416\tvalid_1's auc: 0.840455\tvalid_1's binary_logloss: 0.111202\n",
      "[18]\ttraining's auc: 0.984076\ttraining's binary_logloss: 0.0628442\tvalid_1's auc: 0.838755\tvalid_1's binary_logloss: 0.111225\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's auc: 0.948664\ttraining's binary_logloss: 0.0885702\tvalid_1's auc: 0.847291\tvalid_1's binary_logloss: 0.116238\n",
      "[1]\ttraining's auc: 0.828401\ttraining's binary_logloss: 0.127512\tvalid_1's auc: 0.800866\tvalid_1's binary_logloss: 0.145213\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.889625\ttraining's binary_logloss: 0.117937\tvalid_1's auc: 0.862779\tvalid_1's binary_logloss: 0.141221\n",
      "[3]\ttraining's auc: 0.903421\ttraining's binary_logloss: 0.10978\tvalid_1's auc: 0.86354\tvalid_1's binary_logloss: 0.138003\n",
      "[4]\ttraining's auc: 0.910517\ttraining's binary_logloss: 0.104207\tvalid_1's auc: 0.861033\tvalid_1's binary_logloss: 0.135102\n",
      "[5]\ttraining's auc: 0.916013\ttraining's binary_logloss: 0.0991927\tvalid_1's auc: 0.863572\tvalid_1's binary_logloss: 0.132391\n",
      "[6]\ttraining's auc: 0.924526\ttraining's binary_logloss: 0.0945074\tvalid_1's auc: 0.859436\tvalid_1's binary_logloss: 0.131091\n",
      "[7]\ttraining's auc: 0.932278\ttraining's binary_logloss: 0.0906399\tvalid_1's auc: 0.858782\tvalid_1's binary_logloss: 0.130205\n",
      "[8]\ttraining's auc: 0.945062\ttraining's binary_logloss: 0.0867155\tvalid_1's auc: 0.866187\tvalid_1's binary_logloss: 0.129252\n",
      "[9]\ttraining's auc: 0.953673\ttraining's binary_logloss: 0.0830637\tvalid_1's auc: 0.873837\tvalid_1's binary_logloss: 0.12828\n",
      "[10]\ttraining's auc: 0.960442\ttraining's binary_logloss: 0.0798281\tvalid_1's auc: 0.871266\tvalid_1's binary_logloss: 0.128204\n",
      "[11]\ttraining's auc: 0.964973\ttraining's binary_logloss: 0.07694\tvalid_1's auc: 0.868105\tvalid_1's binary_logloss: 0.128047\n",
      "[12]\ttraining's auc: 0.970824\ttraining's binary_logloss: 0.074285\tvalid_1's auc: 0.870751\tvalid_1's binary_logloss: 0.126949\n",
      "[13]\ttraining's auc: 0.971795\ttraining's binary_logloss: 0.0720265\tvalid_1's auc: 0.872991\tvalid_1's binary_logloss: 0.126611\n",
      "[14]\ttraining's auc: 0.976347\ttraining's binary_logloss: 0.0695999\tvalid_1's auc: 0.875605\tvalid_1's binary_logloss: 0.125382\n",
      "[15]\ttraining's auc: 0.978873\ttraining's binary_logloss: 0.0671712\tvalid_1's auc: 0.875338\tvalid_1's binary_logloss: 0.124989\n",
      "[16]\ttraining's auc: 0.979987\ttraining's binary_logloss: 0.0651251\tvalid_1's auc: 0.875048\tvalid_1's binary_logloss: 0.124538\n",
      "[17]\ttraining's auc: 0.982024\ttraining's binary_logloss: 0.0630024\tvalid_1's auc: 0.873987\tvalid_1's binary_logloss: 0.124428\n",
      "[18]\ttraining's auc: 0.983759\ttraining's binary_logloss: 0.0610347\tvalid_1's auc: 0.87418\tvalid_1's binary_logloss: 0.123756\n",
      "[19]\ttraining's auc: 0.9887\ttraining's binary_logloss: 0.0590933\tvalid_1's auc: 0.875177\tvalid_1's binary_logloss: 0.123559\n",
      "[20]\ttraining's auc: 0.992293\ttraining's binary_logloss: 0.0572266\tvalid_1's auc: 0.873795\tvalid_1's binary_logloss: 0.123293\n",
      "[21]\ttraining's auc: 0.994402\ttraining's binary_logloss: 0.0550725\tvalid_1's auc: 0.871566\tvalid_1's binary_logloss: 0.122871\n",
      "[22]\ttraining's auc: 0.996193\ttraining's binary_logloss: 0.0533527\tvalid_1's auc: 0.869326\tvalid_1's binary_logloss: 0.12259\n",
      "[23]\ttraining's auc: 0.996812\ttraining's binary_logloss: 0.0518003\tvalid_1's auc: 0.867998\tvalid_1's binary_logloss: 0.12265\n",
      "[24]\ttraining's auc: 0.997908\ttraining's binary_logloss: 0.050448\tvalid_1's auc: 0.866015\tvalid_1's binary_logloss: 0.122709\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.976347\ttraining's binary_logloss: 0.0695999\tvalid_1's auc: 0.875605\tvalid_1's binary_logloss: 0.125382\n",
      "[1]\ttraining's auc: 0.846856\ttraining's binary_logloss: 0.125245\tvalid_1's auc: 0.777096\tvalid_1's binary_logloss: 0.162468\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.87742\ttraining's binary_logloss: 0.115178\tvalid_1's auc: 0.786984\tvalid_1's binary_logloss: 0.1542\n",
      "[3]\ttraining's auc: 0.900885\ttraining's binary_logloss: 0.107888\tvalid_1's auc: 0.799921\tvalid_1's binary_logloss: 0.152399\n",
      "[4]\ttraining's auc: 0.919166\ttraining's binary_logloss: 0.101717\tvalid_1's auc: 0.805548\tvalid_1's binary_logloss: 0.150506\n",
      "[5]\ttraining's auc: 0.924758\ttraining's binary_logloss: 0.0966047\tvalid_1's auc: 0.81105\tvalid_1's binary_logloss: 0.147827\n",
      "[6]\ttraining's auc: 0.936364\ttraining's binary_logloss: 0.0917999\tvalid_1's auc: 0.815946\tvalid_1's binary_logloss: 0.145145\n",
      "[7]\ttraining's auc: 0.949072\ttraining's binary_logloss: 0.0878871\tvalid_1's auc: 0.830278\tvalid_1's binary_logloss: 0.143619\n",
      "[8]\ttraining's auc: 0.953706\ttraining's binary_logloss: 0.0841049\tvalid_1's auc: 0.829835\tvalid_1's binary_logloss: 0.142998\n",
      "[9]\ttraining's auc: 0.958085\ttraining's binary_logloss: 0.0804773\tvalid_1's auc: 0.830268\tvalid_1's binary_logloss: 0.142683\n",
      "[10]\ttraining's auc: 0.960056\ttraining's binary_logloss: 0.0774027\tvalid_1's auc: 0.834202\tvalid_1's binary_logloss: 0.141057\n",
      "[11]\ttraining's auc: 0.964575\ttraining's binary_logloss: 0.0746281\tvalid_1's auc: 0.831249\tvalid_1's binary_logloss: 0.140879\n",
      "[12]\ttraining's auc: 0.966815\ttraining's binary_logloss: 0.072048\tvalid_1's auc: 0.830355\tvalid_1's binary_logloss: 0.14037\n",
      "[13]\ttraining's auc: 0.969269\ttraining's binary_logloss: 0.0692412\tvalid_1's auc: 0.831749\tvalid_1's binary_logloss: 0.139711\n",
      "[14]\ttraining's auc: 0.971753\ttraining's binary_logloss: 0.0666855\tvalid_1's auc: 0.827748\tvalid_1's binary_logloss: 0.140026\n",
      "[15]\ttraining's auc: 0.975599\ttraining's binary_logloss: 0.064564\tvalid_1's auc: 0.824757\tvalid_1's binary_logloss: 0.140325\n",
      "[16]\ttraining's auc: 0.976757\ttraining's binary_logloss: 0.0624919\tvalid_1's auc: 0.825901\tvalid_1's binary_logloss: 0.139913\n",
      "[17]\ttraining's auc: 0.982245\ttraining's binary_logloss: 0.0605416\tvalid_1's auc: 0.824391\tvalid_1's binary_logloss: 0.139645\n",
      "[18]\ttraining's auc: 0.987209\ttraining's binary_logloss: 0.0584455\tvalid_1's auc: 0.818591\tvalid_1's binary_logloss: 0.139097\n",
      "[19]\ttraining's auc: 0.988904\ttraining's binary_logloss: 0.0566856\tvalid_1's auc: 0.820409\tvalid_1's binary_logloss: 0.13906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's auc: 0.989518\ttraining's binary_logloss: 0.0550298\tvalid_1's auc: 0.824199\tvalid_1's binary_logloss: 0.138727\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's auc: 0.960056\ttraining's binary_logloss: 0.0774027\tvalid_1's auc: 0.834202\tvalid_1's binary_logloss: 0.141057\n",
      "[1]\ttraining's auc: 0.839059\ttraining's binary_logloss: 0.126962\tvalid_1's auc: 0.769134\tvalid_1's binary_logloss: 0.161285\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.855181\ttraining's binary_logloss: 0.116815\tvalid_1's auc: 0.817048\tvalid_1's binary_logloss: 0.158551\n",
      "[3]\ttraining's auc: 0.885989\ttraining's binary_logloss: 0.109325\tvalid_1's auc: 0.82514\tvalid_1's binary_logloss: 0.156416\n",
      "[4]\ttraining's auc: 0.894017\ttraining's binary_logloss: 0.102515\tvalid_1's auc: 0.820658\tvalid_1's binary_logloss: 0.155327\n",
      "[5]\ttraining's auc: 0.907071\ttraining's binary_logloss: 0.0975088\tvalid_1's auc: 0.833734\tvalid_1's binary_logloss: 0.153655\n",
      "[6]\ttraining's auc: 0.911484\ttraining's binary_logloss: 0.0927207\tvalid_1's auc: 0.836542\tvalid_1's binary_logloss: 0.15122\n",
      "[7]\ttraining's auc: 0.936524\ttraining's binary_logloss: 0.088658\tvalid_1's auc: 0.8392\tvalid_1's binary_logloss: 0.149804\n",
      "[8]\ttraining's auc: 0.94877\ttraining's binary_logloss: 0.0850063\tvalid_1's auc: 0.838989\tvalid_1's binary_logloss: 0.148583\n",
      "[9]\ttraining's auc: 0.951709\ttraining's binary_logloss: 0.0819487\tvalid_1's auc: 0.836001\tvalid_1's binary_logloss: 0.14759\n",
      "[10]\ttraining's auc: 0.955637\ttraining's binary_logloss: 0.0790934\tvalid_1's auc: 0.837194\tvalid_1's binary_logloss: 0.146674\n",
      "[11]\ttraining's auc: 0.963198\ttraining's binary_logloss: 0.0760658\tvalid_1's auc: 0.845517\tvalid_1's binary_logloss: 0.145123\n",
      "[12]\ttraining's auc: 0.965354\ttraining's binary_logloss: 0.0733416\tvalid_1's auc: 0.839902\tvalid_1's binary_logloss: 0.145182\n",
      "[13]\ttraining's auc: 0.969419\ttraining's binary_logloss: 0.0708353\tvalid_1's auc: 0.842609\tvalid_1's binary_logloss: 0.144048\n",
      "[14]\ttraining's auc: 0.970937\ttraining's binary_logloss: 0.0686102\tvalid_1's auc: 0.846059\tvalid_1's binary_logloss: 0.143555\n",
      "[15]\ttraining's auc: 0.976675\ttraining's binary_logloss: 0.0661782\tvalid_1's auc: 0.846982\tvalid_1's binary_logloss: 0.142814\n",
      "[16]\ttraining's auc: 0.981377\ttraining's binary_logloss: 0.0640257\tvalid_1's auc: 0.859878\tvalid_1's binary_logloss: 0.14202\n",
      "[17]\ttraining's auc: 0.982778\ttraining's binary_logloss: 0.0620554\tvalid_1's auc: 0.859527\tvalid_1's binary_logloss: 0.142253\n",
      "[18]\ttraining's auc: 0.98497\ttraining's binary_logloss: 0.060312\tvalid_1's auc: 0.856338\tvalid_1's binary_logloss: 0.142799\n",
      "[19]\ttraining's auc: 0.989702\ttraining's binary_logloss: 0.0581387\tvalid_1's auc: 0.854974\tvalid_1's binary_logloss: 0.142659\n",
      "[20]\ttraining's auc: 0.991013\ttraining's binary_logloss: 0.0563258\tvalid_1's auc: 0.853851\tvalid_1's binary_logloss: 0.142694\n",
      "[21]\ttraining's auc: 0.993196\ttraining's binary_logloss: 0.0545751\tvalid_1's auc: 0.852647\tvalid_1's binary_logloss: 0.142867\n",
      "[22]\ttraining's auc: 0.994034\ttraining's binary_logloss: 0.0529083\tvalid_1's auc: 0.851805\tvalid_1's binary_logloss: 0.143125\n",
      "[23]\ttraining's auc: 0.996154\ttraining's binary_logloss: 0.0513691\tvalid_1's auc: 0.850722\tvalid_1's binary_logloss: 0.143115\n",
      "[24]\ttraining's auc: 0.996674\ttraining's binary_logloss: 0.0499259\tvalid_1's auc: 0.854252\tvalid_1's binary_logloss: 0.143007\n",
      "[25]\ttraining's auc: 0.997552\ttraining's binary_logloss: 0.0485222\tvalid_1's auc: 0.85365\tvalid_1's binary_logloss: 0.143137\n",
      "[26]\ttraining's auc: 0.99836\ttraining's binary_logloss: 0.047138\tvalid_1's auc: 0.855315\tvalid_1's binary_logloss: 0.142963\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.981377\ttraining's binary_logloss: 0.0640257\tvalid_1's auc: 0.859878\tvalid_1's binary_logloss: 0.14202\n",
      "[1]\ttraining's auc: 0.839361\ttraining's binary_logloss: 0.127713\tvalid_1's auc: 0.733713\tvalid_1's binary_logloss: 0.149843\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.881919\ttraining's binary_logloss: 0.117005\tvalid_1's auc: 0.772877\tvalid_1's binary_logloss: 0.147639\n",
      "[3]\ttraining's auc: 0.895964\ttraining's binary_logloss: 0.10942\tvalid_1's auc: 0.785854\tvalid_1's binary_logloss: 0.144571\n",
      "[4]\ttraining's auc: 0.910313\ttraining's binary_logloss: 0.103141\tvalid_1's auc: 0.797233\tvalid_1's binary_logloss: 0.142521\n",
      "[5]\ttraining's auc: 0.921453\ttraining's binary_logloss: 0.0977817\tvalid_1's auc: 0.793762\tvalid_1's binary_logloss: 0.142646\n",
      "[6]\ttraining's auc: 0.927557\ttraining's binary_logloss: 0.0927861\tvalid_1's auc: 0.788918\tvalid_1's binary_logloss: 0.142551\n",
      "[7]\ttraining's auc: 0.94402\ttraining's binary_logloss: 0.0886896\tvalid_1's auc: 0.792229\tvalid_1's binary_logloss: 0.141663\n",
      "[8]\ttraining's auc: 0.954517\ttraining's binary_logloss: 0.0848218\tvalid_1's auc: 0.790129\tvalid_1's binary_logloss: 0.141264\n",
      "[9]\ttraining's auc: 0.959008\ttraining's binary_logloss: 0.0814199\tvalid_1's auc: 0.786175\tvalid_1's binary_logloss: 0.141343\n",
      "[10]\ttraining's auc: 0.964978\ttraining's binary_logloss: 0.0781992\tvalid_1's auc: 0.787911\tvalid_1's binary_logloss: 0.14077\n",
      "[11]\ttraining's auc: 0.96704\ttraining's binary_logloss: 0.0751954\tvalid_1's auc: 0.798787\tvalid_1's binary_logloss: 0.140178\n",
      "[12]\ttraining's auc: 0.969557\ttraining's binary_logloss: 0.0727613\tvalid_1's auc: 0.798187\tvalid_1's binary_logloss: 0.140147\n",
      "[13]\ttraining's auc: 0.972669\ttraining's binary_logloss: 0.0703353\tvalid_1's auc: 0.799644\tvalid_1's binary_logloss: 0.139438\n",
      "[14]\ttraining's auc: 0.978056\ttraining's binary_logloss: 0.067763\tvalid_1's auc: 0.79779\tvalid_1's binary_logloss: 0.139932\n",
      "[15]\ttraining's auc: 0.979311\ttraining's binary_logloss: 0.0654841\tvalid_1's auc: 0.797501\tvalid_1's binary_logloss: 0.139902\n",
      "[16]\ttraining's auc: 0.984466\ttraining's binary_logloss: 0.0631111\tvalid_1's auc: 0.794265\tvalid_1's binary_logloss: 0.139815\n",
      "[17]\ttraining's auc: 0.98601\ttraining's binary_logloss: 0.0612543\tvalid_1's auc: 0.792711\tvalid_1's binary_logloss: 0.140046\n",
      "[18]\ttraining's auc: 0.986791\ttraining's binary_logloss: 0.0596033\tvalid_1's auc: 0.796055\tvalid_1's binary_logloss: 0.139672\n",
      "[19]\ttraining's auc: 0.988997\ttraining's binary_logloss: 0.0579334\tvalid_1's auc: 0.796569\tvalid_1's binary_logloss: 0.139197\n",
      "[20]\ttraining's auc: 0.991466\ttraining's binary_logloss: 0.0561758\tvalid_1's auc: 0.794597\tvalid_1's binary_logloss: 0.139586\n",
      "[21]\ttraining's auc: 0.992772\ttraining's binary_logloss: 0.054496\tvalid_1's auc: 0.805002\tvalid_1's binary_logloss: 0.139291\n",
      "[22]\ttraining's auc: 0.994962\ttraining's binary_logloss: 0.0527221\tvalid_1's auc: 0.803137\tvalid_1's binary_logloss: 0.13971\n",
      "[23]\ttraining's auc: 0.996215\ttraining's binary_logloss: 0.0511548\tvalid_1's auc: 0.803073\tvalid_1's binary_logloss: 0.139822\n",
      "[24]\ttraining's auc: 0.997181\ttraining's binary_logloss: 0.0497925\tvalid_1's auc: 0.801187\tvalid_1's binary_logloss: 0.140225\n",
      "[25]\ttraining's auc: 0.998295\ttraining's binary_logloss: 0.0481351\tvalid_1's auc: 0.809652\tvalid_1's binary_logloss: 0.140385\n",
      "[26]\ttraining's auc: 0.998534\ttraining's binary_logloss: 0.0467569\tvalid_1's auc: 0.808795\tvalid_1's binary_logloss: 0.140932\n",
      "[27]\ttraining's auc: 0.998899\ttraining's binary_logloss: 0.0455071\tvalid_1's auc: 0.807595\tvalid_1's binary_logloss: 0.141268\n",
      "[28]\ttraining's auc: 0.999212\ttraining's binary_logloss: 0.0442665\tvalid_1's auc: 0.806995\tvalid_1's binary_logloss: 0.141456\n",
      "[29]\ttraining's auc: 0.999348\ttraining's binary_logloss: 0.0431825\tvalid_1's auc: 0.805902\tvalid_1's binary_logloss: 0.141888\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.988997\ttraining's binary_logloss: 0.0579334\tvalid_1's auc: 0.796569\tvalid_1's binary_logloss: 0.139197\n",
      "[1]\ttraining's auc: 0.86388\ttraining's binary_logloss: 0.131189\tvalid_1's auc: 0.762689\tvalid_1's binary_logloss: 0.128259\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.897432\ttraining's binary_logloss: 0.120408\tvalid_1's auc: 0.802624\tvalid_1's binary_logloss: 0.12513\n",
      "[3]\ttraining's auc: 0.908798\ttraining's binary_logloss: 0.112265\tvalid_1's auc: 0.807075\tvalid_1's binary_logloss: 0.122789\n",
      "[4]\ttraining's auc: 0.919608\ttraining's binary_logloss: 0.105659\tvalid_1's auc: 0.804031\tvalid_1's binary_logloss: 0.120656\n",
      "[5]\ttraining's auc: 0.927876\ttraining's binary_logloss: 0.100001\tvalid_1's auc: 0.811282\tvalid_1's binary_logloss: 0.118988\n",
      "[6]\ttraining's auc: 0.940515\ttraining's binary_logloss: 0.0953834\tvalid_1's auc: 0.81043\tvalid_1's binary_logloss: 0.117574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttraining's auc: 0.9495\ttraining's binary_logloss: 0.0911054\tvalid_1's auc: 0.807319\tvalid_1's binary_logloss: 0.117022\n",
      "[8]\ttraining's auc: 0.957123\ttraining's binary_logloss: 0.0874409\tvalid_1's auc: 0.803923\tvalid_1's binary_logloss: 0.116797\n",
      "[9]\ttraining's auc: 0.965395\ttraining's binary_logloss: 0.0839852\tvalid_1's auc: 0.807319\tvalid_1's binary_logloss: 0.11573\n",
      "[10]\ttraining's auc: 0.969309\ttraining's binary_logloss: 0.0807899\tvalid_1's auc: 0.806318\tvalid_1's binary_logloss: 0.115055\n",
      "[11]\ttraining's auc: 0.97293\ttraining's binary_logloss: 0.0778034\tvalid_1's auc: 0.80529\tvalid_1's binary_logloss: 0.114656\n",
      "[12]\ttraining's auc: 0.975954\ttraining's binary_logloss: 0.0750712\tvalid_1's auc: 0.804072\tvalid_1's binary_logloss: 0.11442\n",
      "[13]\ttraining's auc: 0.977927\ttraining's binary_logloss: 0.0724275\tvalid_1's auc: 0.800798\tvalid_1's binary_logloss: 0.114642\n",
      "[14]\ttraining's auc: 0.979601\ttraining's binary_logloss: 0.0699878\tvalid_1's auc: 0.800122\tvalid_1's binary_logloss: 0.114705\n",
      "[15]\ttraining's auc: 0.98253\ttraining's binary_logloss: 0.0676686\tvalid_1's auc: 0.802029\tvalid_1's binary_logloss: 0.114097\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.927876\ttraining's binary_logloss: 0.100001\tvalid_1's auc: 0.811282\tvalid_1's binary_logloss: 0.118988\n",
      "[1]\ttraining's auc: 0.832127\ttraining's binary_logloss: 0.130878\tvalid_1's auc: 0.829459\tvalid_1's binary_logloss: 0.11561\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's auc: 0.865696\ttraining's binary_logloss: 0.120315\tvalid_1's auc: 0.836399\tvalid_1's binary_logloss: 0.11154\n",
      "[3]\ttraining's auc: 0.894087\ttraining's binary_logloss: 0.112649\tvalid_1's auc: 0.846225\tvalid_1's binary_logloss: 0.109139\n",
      "[4]\ttraining's auc: 0.911602\ttraining's binary_logloss: 0.106282\tvalid_1's auc: 0.849572\tvalid_1's binary_logloss: 0.107814\n",
      "[5]\ttraining's auc: 0.923018\ttraining's binary_logloss: 0.100683\tvalid_1's auc: 0.847791\tvalid_1's binary_logloss: 0.106233\n",
      "[6]\ttraining's auc: 0.930613\ttraining's binary_logloss: 0.0959574\tvalid_1's auc: 0.851199\tvalid_1's binary_logloss: 0.10487\n",
      "[7]\ttraining's auc: 0.938193\ttraining's binary_logloss: 0.0919601\tvalid_1's auc: 0.853579\tvalid_1's binary_logloss: 0.103911\n",
      "[8]\ttraining's auc: 0.951676\ttraining's binary_logloss: 0.0879185\tvalid_1's auc: 0.862038\tvalid_1's binary_logloss: 0.102593\n",
      "[9]\ttraining's auc: 0.957353\ttraining's binary_logloss: 0.0845727\tvalid_1's auc: 0.862821\tvalid_1's binary_logloss: 0.102209\n",
      "[10]\ttraining's auc: 0.963449\ttraining's binary_logloss: 0.081209\tvalid_1's auc: 0.861071\tvalid_1's binary_logloss: 0.102024\n",
      "[11]\ttraining's auc: 0.965276\ttraining's binary_logloss: 0.0784943\tvalid_1's auc: 0.861654\tvalid_1's binary_logloss: 0.101498\n",
      "[12]\ttraining's auc: 0.967866\ttraining's binary_logloss: 0.0758332\tvalid_1's auc: 0.862913\tvalid_1's binary_logloss: 0.101005\n",
      "[13]\ttraining's auc: 0.971333\ttraining's binary_logloss: 0.0733536\tvalid_1's auc: 0.8656\tvalid_1's binary_logloss: 0.100019\n",
      "[14]\ttraining's auc: 0.975042\ttraining's binary_logloss: 0.0709602\tvalid_1's auc: 0.865846\tvalid_1's binary_logloss: 0.0998168\n",
      "[15]\ttraining's auc: 0.977468\ttraining's binary_logloss: 0.068885\tvalid_1's auc: 0.864955\tvalid_1's binary_logloss: 0.0992975\n",
      "[16]\ttraining's auc: 0.979971\ttraining's binary_logloss: 0.0666993\tvalid_1's auc: 0.86537\tvalid_1's binary_logloss: 0.0985932\n",
      "[17]\ttraining's auc: 0.98077\ttraining's binary_logloss: 0.0646639\tvalid_1's auc: 0.865247\tvalid_1's binary_logloss: 0.0983472\n",
      "[18]\ttraining's auc: 0.98254\ttraining's binary_logloss: 0.0628798\tvalid_1's auc: 0.863466\tvalid_1's binary_logloss: 0.0984384\n",
      "[19]\ttraining's auc: 0.989021\ttraining's binary_logloss: 0.0607064\tvalid_1's auc: 0.857924\tvalid_1's binary_logloss: 0.0983949\n",
      "[20]\ttraining's auc: 0.99112\ttraining's binary_logloss: 0.059034\tvalid_1's auc: 0.857187\tvalid_1's binary_logloss: 0.0981851\n",
      "[21]\ttraining's auc: 0.992371\ttraining's binary_logloss: 0.0572845\tvalid_1's auc: 0.859766\tvalid_1's binary_logloss: 0.0970895\n",
      "[22]\ttraining's auc: 0.994194\ttraining's binary_logloss: 0.055504\tvalid_1's auc: 0.859597\tvalid_1's binary_logloss: 0.0969605\n",
      "[23]\ttraining's auc: 0.995193\ttraining's binary_logloss: 0.0539395\tvalid_1's auc: 0.859536\tvalid_1's binary_logloss: 0.0967072\n",
      "[24]\ttraining's auc: 0.996596\ttraining's binary_logloss: 0.0525047\tvalid_1's auc: 0.860349\tvalid_1's binary_logloss: 0.0967989\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.975042\ttraining's binary_logloss: 0.0709602\tvalid_1's auc: 0.865846\tvalid_1's binary_logloss: 0.0998168\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "fi = [] # objeto vacío para guardar la importancia de las variables de los modelos entrenados\n",
    "test_probs = [] # objeto vacío para guardar las probabilidades estimadas\n",
    "i = 0 \n",
    "for train_idx, valid_idx in model_selection.KFold(n_splits=10, shuffle=True).split(X_train):\n",
    "    i += 1\n",
    "    Xt = X_train.iloc[train_idx]\n",
    "    yt = y_train.loc[X_train.index].iloc[train_idx]\n",
    "\n",
    "    Xv = X_train.iloc[valid_idx]\n",
    "    yv = y_train.loc[X_train.index].iloc[valid_idx]\n",
    "\n",
    "    learner = LGBMClassifier(n_estimators=10000) # lightgbm with max 10.000 trees\n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                eval_set=[(Xt, yt), (Xv, yv)])\n",
    "    \n",
    "    test_probs.append(pd.Series(learner.predict_proba(X_test)[:, -1],\n",
    "                                index=X_test.index, name=\"fold_\" + str(i)))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1) # mean of probabilities\n",
    "test_probs.index.name=\"USER_ID\"\n",
    "test_probs.name=\"SCORE\"\n",
    "test_probs.to_csv(\"respuesta\", header=True, compression=\"zip\")\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1) # Variables as explanation of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lado B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train set and Test set\n",
    "\n",
    "We split the test set, so we use last three months to test (Given that original test set is not given to competitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo PAGE\n",
      "haciendo CONTENT_CATEGORY\n",
      "haciendo CONTENT_CATEGORY_TOP\n",
      "haciendo CONTENT_CATEGORY_BOTTOM\n",
      "haciendo SITE_ID\n",
      "haciendo ON_SITE_SEARCH_TERM\n"
     ]
    }
   ],
   "source": [
    "data = data[data.FEC_EVENT.dt.month < 10]\n",
    "X_test2 = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_test2.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_test2 = pd.concat(X_test2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo PAGE\n",
      "haciendo CONTENT_CATEGORY\n",
      "haciendo CONTENT_CATEGORY_TOP\n",
      "haciendo CONTENT_CATEGORY_BOTTOM\n",
      "haciendo SITE_ID\n",
      "haciendo ON_SITE_SEARCH_TERM\n"
     ]
    }
   ],
   "source": [
    "data = data[(data.FEC_EVENT.dt.month < 7)]\n",
    "X_train2 = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_train2.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_train2 = pd.concat(X_train2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev2 = pd.read_csv(\"./data/conversiones.csv\")\n",
    "y_test2 = pd.Series(0, index=X_test2.index)\n",
    "idx = set(y_prev2[y_prev2.mes >= 10].USER_ID.unique()).intersection(set(X_test2.index))\n",
    "y_test2.loc[list(idx)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = pd.Series(0, index=X_train2.index)\n",
    "idx = set(y_prev2[(y_prev2.mes < 10) & (y_prev2.mes > 6)].USER_ID.unique()).intersection(set(X_train2.index))\n",
    "y_train2.loc[list(idx)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1890) (11314,) (11529, 2026) (11529,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape, y_train2.shape, X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(X_train2.columns).intersection(set(X_test2.columns)))\n",
    "X_train2 = X_train2[features]\n",
    "X_test2 = X_test2[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1890)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca2 = PCA(0.99,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=23,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2.fit(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca2 = pd.DataFrame(pca2.transform(X_train2))\n",
    "X_test_pca2 = pd.DataFrame(pca2.transform(X_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 43) (11529, 43)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca2.shape, X_test_pca2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training and validating\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selected_features = SelectKBest(chi2,k=200)\n",
    "selected_features.fit(X_train2, y_train2)\n",
    "X_train_skb2 = pd.DataFrame(selected_features.transform(X_train2))\n",
    "X_test_skb2 = pd.DataFrame(selected_features.transform(X_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_VALUES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_N</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0.00064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.00272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.00312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>0.02693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>0.99974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>0.99976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0.99981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>0.99983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1890 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        P_VALUES\n",
       "FEAT_N          \n",
       "692      0.00005\n",
       "1842     0.00064\n",
       "1014     0.00272\n",
       "791      0.00312\n",
       "1320     0.02693\n",
       "...          ...\n",
       "1111     0.99974\n",
       "1861     0.99976\n",
       "1565     0.99981\n",
       "1245     0.99983\n",
       "190      0.99999\n",
       "\n",
       "[1890 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values = pd.DataFrame(selected_features.pvalues_.round(5))\n",
    "p_values.index.name=\"FEAT_N\"\n",
    "p_values.columns = [\"P_VALUES\"]\n",
    "p_values.sort_values(by=['P_VALUES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAT_N</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>16.40521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>11.64837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>8.98474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>8.73733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>4.89520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1890 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SCORE\n",
       "FEAT_N          \n",
       "692     16.40521\n",
       "1842    11.64837\n",
       "1014     8.98474\n",
       "791      8.73733\n",
       "1090     4.89520\n",
       "...          ...\n",
       "625      0.00000\n",
       "1565     0.00000\n",
       "1245     0.00000\n",
       "1556     0.00000\n",
       "671      0.00000\n",
       "\n",
       "[1890 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(selected_features.scores_.round(5))\n",
    "df.index.name=\"FEAT_N\"\n",
    "df.columns = [\"SCORE\"]\n",
    "df.sort_values(by=['SCORE'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing\n",
    "\n",
    "selected_features = SelectKBest(chi2,k=200)\n",
    "selected_features.fit(X_train, y_train)\n",
    "X_train_skb_compl = pd.DataFrame(selected_features.transform(X_train))\n",
    "X_test_skb_compl = pd.DataFrame(selected_features.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=47)\n",
    "\n",
    "params = {\n",
    "    'criterion' : ['gini','entropy'],\n",
    "    'splitter' : ['best','random'],\n",
    "    'max_depth' : [None,3,4,5,8,10],\n",
    "    'max_features' : [None, 10, 25]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(dtc, params, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = gs.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7928467568956268"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=47, splitter='best')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_arbol1 = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=47,\n",
    "            splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor2 = opt_arbol1.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion2 = predictor2.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068575687787587"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "scores = roc_auc_score(y_test2,prediccion2[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2_no_cv = GridSearchCV(dtc,params,scoring='roc_auc',cv=2)\n",
    "gs2_no_cv.fit(X_train2,y_train2)\n",
    "pred_no_cv = gs2_no_cv.best_estimator_\n",
    "predijo = pred_no_cv.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068575687787587"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_no_cv = roc_auc_score(y_test2,predijo[:,1])\n",
    "scores_no_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pca = gs.fit(X_train_pca2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7178605582963131"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pca.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_pca = gs_pca.best_estimator_\n",
    "pred_pca = predictor_pca.predict_proba(X_test_pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7383593018050242"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_pca = roc_auc_score(y_test2,pred_pca[:,1])\n",
    "scores_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_skb = gs.fit(X_train_skb2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904155927293485"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_skb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=47, splitter='best')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_skb = gs_skb.best_estimator_\n",
    "predictor_skb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_skb = predictor_skb.predict_proba(X_test_skb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8234152386314861"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_skb_tree = roc_auc_score(y_test2,predic_skb[:,1])\n",
    "scores_skb_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTR - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol1 = predictor_skb.fit(X_train_skb_compl,y_train)\n",
    "sol_arbol1 = arbol1.predict_proba(X_test_skb_compl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_arbol1 = pd.Series(sol_arbol1[:,1])\n",
    "resultado_arbol1.index.name=\"USER_ID\" # Renombramos las columnas\n",
    "resultado_arbol1.name=\"SCORE\" # Renombramos las columnas\n",
    "resultado_arbol1.to_csv(\"respuesta_arbol_1\", header=True, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTR 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization through GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pg = [\n",
    "    {\"splitter\":[\"best\",\"random\"],\n",
    "     \"max_depth\":[None,1,2,3,4,5,7,10], \n",
    "     \"max_features\":[10,25], \n",
    "     \"max_leaf_nodes\":[10,50,100,150,200]}\n",
    "]\n",
    "\n",
    "dtc2 = arbol1\n",
    "\n",
    "opt = GridSearchCV(dtc2, pg, scoring=\"roc_auc\",n_jobs=-1,cv=StratifiedKFold(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='entropy', max_depth=3,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=47,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'max_depth': [None, 1, 2, 3, 4, 5, 7, 10],\n",
       "                          'max_features': [10, 25],\n",
       "                          'max_leaf_nodes': [10, 50, 100, 150, 200],\n",
       "                          'splitter': ['best', 'random']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64293226737744"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=25, max_leaf_nodes=50,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=47, splitter='best')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_decision_tree = opt.best_estimator_\n",
    "optimised_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = optimised_decision_tree.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7345676434073465"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = roc_auc_score(y_test2,sol[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_arbol2 = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "            max_features=25, max_leaf_nodes=10, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=47, splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_pca = opt.fit(X_train_pca2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7157811656206726"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_pca.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tree_2 = opt_pca.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tree_2 = pca_tree_2.predict_proba(X_test_pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711334591758087"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = roc_auc_score(y_test2,res_tree_2[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_skb = opt.fit(X_train_skb2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7982048480892004"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_skb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "skb_tree_2 = opt_skb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_skb_2 = skb_tree_2.predict_proba(X_test_skb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043135277584194"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = roc_auc_score(y_test2,sol_skb_2[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTR2 - solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=10, max_leaf_nodes=10,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=47, splitter='best')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol2 = skb_tree_2\n",
    "skb_tree_2.fit(X_train_skb_compl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_a2 = skb_tree_2.predict_proba(X_test_skb_compl)\n",
    "resultado_arbol2 = pd.Series(sol_a2[:,1])\n",
    "resultado_arbol2.index.name=\"USER_ID\" # Renombramos las columnas\n",
    "resultado_arbol2.name=\"SCORE\" # Renombramos las columnas\n",
    "resultado_arbol2.to_csv(\"respuesta_arbol_2\", header=True, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=8, random_state=23)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators = 8,random_state=23)\n",
    "clf.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "probab = clf.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264840335436348"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = roc_auc_score(y_test2,probab[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7574733584710601"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pca = clf.fit(X_train_pca2,y_train2)\n",
    "probab_pca = clf_pca.predict_proba(X_test_pca2)\n",
    "scores = roc_auc_score(y_test2,probab_pca[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264840335436348"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_skb = clf.fit(X_train_skb2,y_train2)\n",
    "probab_skb = clf_skb.predict_proba(X_test_skb2)\n",
    "scores = roc_auc_score(y_test2,probab_skb[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=8, random_state=23)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_cut = AdaBoostClassifier(n_estimators = 8,random_state=23)\n",
    "ada_cut.fit(X_train_cut1,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264840335436348"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_ada_cut = ada_cut.predict_proba(X_test_cut1)\n",
    "sco_ada_cut = roc_auc_score(y_test2,sol_ada_cut[:,1])\n",
    "sco_ada_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADABOOST - solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=8, random_state=23)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_final = AdaBoostClassifier(n_estimators = 8,random_state=23)\n",
    "ada_final.fit(X_train_skb_compl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_ada_final = ada_final.predict_proba(X_test_skb_compl)\n",
    "resultado_ada = pd.Series(sol_ada_final[:,1])\n",
    "resultado_ada.index.name=\"USER_ID\" # Renombramos las columnas\n",
    "resultado_ada.name=\"SCORE\" # Renombramos las columnas\n",
    "resultado_ada.to_csv(\"respuesta_ada\", header=True, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\" : [200,500,1000],\n",
    "    \"max_depth\" : [3,4],\n",
    "    \"max_features\" : [50,100,200],\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=47,class_weight=\"balanced\",criterion='gini')\n",
    "\n",
    "clasificador = GridSearchCV(random_forest,param_grid,scoring=\"roc_auc\",cv=StratifiedKFold(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest2 = clasificador.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8336114567943088 RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=4, max_features=100,\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=1000, n_jobs=None, oob_score=False,\n",
      "                       random_state=47, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(forest2.best_score_,forest2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_for2 = forest2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571051769255976"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_rf2 = clf_for2.predict_proba(X_test2)\n",
    "scores = roc_auc_score(y_test2,sol_rf2[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt = RandomForestClassifier(random_state=47,class_weight=\"balanced\",criterion='gini',n_estimators=200,max_features=100,max_depth=4)\n",
    "rf_opt_pca = RandomForestClassifier(random_state=47,class_weight=\"balanced\",criterion='gini',n_estimators=200,max_depth=4)\n",
    "rf_opt_skb = RandomForestClassifier(random_state=47,class_weight=\"balanced\",criterion='gini',n_estimators=200,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                       random_state=47, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_opt_pca.fit(X_train_pca2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8060365158556902"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_rf22 = rf_opt_pca.predict_proba(X_test_pca2)\n",
    "scores22 = roc_auc_score(y_test2,sol_rf22[:,1])\n",
    "scores22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                       random_state=47, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_opt_skb.fit(X_train_skb2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560607459166577"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_rf_skb = rf_opt_skb.predict_proba(X_test_skb2)\n",
    "scores = roc_auc_score(y_test2,sol_rf_skb[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF - solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                       random_state=47, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_final = RandomForestClassifier(random_state=47,class_weight=\"balanced\",criterion='gini',n_estimators=200,max_depth=4)\n",
    "rf_final.fit(X_train_skb_compl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_sol = rf_final.predict_proba(X_test_skb_compl)\n",
    "resultado_random = pd.Series(rf_final_sol[:,1])\n",
    "resultado_random.index.name=\"USER_ID\" # Renombramos las columnas\n",
    "resultado_random.name=\"SCORE\" # Renombramos las columnas\n",
    "resultado_random.to_csv(\"respuesta_random\", header=True, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(random_seed=47,verbose=0)\n",
    "\n",
    "grid_cat = {\n",
    "    \"iterations\": [50,100,200],\n",
    "    \"max_depth\": [None,2,4,6],\n",
    "}\n",
    "\n",
    "cat_clf = GridSearchCV(cat,grid_cat,cv=StratifiedKFold(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x7fd4fbfa2450>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'iterations': [50, 100, 200],\n",
       "                         'max_depth': [None, 2, 4, 6]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fd4fcc4ac10>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488736483087418"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_cat2 = cat_clf.best_estimator_\n",
    "sol_cat2 = mod_cat2.predict_proba(X_test2)\n",
    "sco = roc_auc_score(y_test2, sol_cat2[:,1])\n",
    "sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541641090491201"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "mod_cat_nogs = CatBoostClassifier(iterations=220,random_seed=47,max_depth=None,verbose=0)\n",
    "mod_cat_nogs.fit(X_train2,y_train2)\n",
    "sol_cat_nogs = mod_cat_nogs.predict_proba(X_test2)\n",
    "sco_cat_nogs = roc_auc_score(y_test2,sol_cat_nogs[:,1])\n",
    "sco_cat_nogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8476981442080925"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_cat_skb = CatBoostClassifier(iterations=220,random_seed=47,max_depth=None,verbose=0)\n",
    "mod_cat_skb.fit(X_train_skb2,y_train2)\n",
    "sol_cat_skb = mod_cat_skb.predict_proba(X_test_skb2)\n",
    "sco_cat_skb = roc_auc_score(y_test2,sol_cat_skb[:,1])\n",
    "sco_cat_skb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8495218601302424"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otro_cat_skb = CatBoostClassifier(iterations=220,random_seed=47,max_depth=None,verbose=0)\n",
    "otro_cat_skb.fit(X_train_cut1,y_train2)\n",
    "sol_otro_cat = otro_cat_skb.predict_proba(X_test_cut1)\n",
    "sco_otro_cat = roc_auc_score(y_test2,sol_otro_cat[:,1])\n",
    "sco_otro_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATBOOST - solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fd4fbbf6d50>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_final = CatBoostClassifier(iterations=220,random_seed=47,max_depth=None,verbose=0)\n",
    "cat_final.fit(X_train_skb_compl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_cat = cat_final.predict_proba(X_test_skb_compl)\n",
    "resultado_cat = pd.Series(sol_cat[:,1])\n",
    "resultado_cat.index.name=\"USER_ID\" # Renombramos las columnas\n",
    "resultado_cat.name=\"SCORE\" # Renombramos las columnas\n",
    "resultado_cat.to_csv(\"respuesta_cat\", header=True, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(verbosity=0,max_depth=2,sub_sample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, sub_sample=0.5, subsample=1, verbosity=0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train_skb2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8535971256224819"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_xgb = xgb_clf.predict_proba(X_test_skb2)\n",
    "sco_xgb = roc_auc_score(y_test2,sol_xgb[:,1])\n",
    "sco_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, sub_sample=0.5, subsample=1, verbosity=0)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final = XGBClassifier(verbosity=0,max_depth=2,sub_sample=0.5)\n",
    "xgb_final.fit(X_train_skb_compl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_xgb = xgb_final.predict_proba(X_test_skb_compl)\n",
    "resultado_xgb = pd.Series(sol_xgb[:,1])\n",
    "resultado_xgb.index.name=\"USER_ID\" # Renombramos las columnas\n",
    "resultado_xgb.name=\"SCORE\" # Renombramos las columnas\n",
    "resultado_xgb.to_csv(\"respuesta_xgb\", header=True, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(class_weight=\"balanced\",probability=True,verbose=1,random_state=99,gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=99, shrinking=True, tol=0.001,\n",
       "    verbose=1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_skb2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6048455506685189"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_prueba = svm.predict_proba(X_test_skb2)\n",
    "scoring_svm = roc_auc_score(y_test2, svm_prueba[:,1])\n",
    "scoring_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "kmeans = KMeans(n_clusters=2,random_state=44,verbose=0)\n",
    "X_train_km = kmeans.fit_transform(X_train_skb2)\n",
    "y_kmeans = kmeans.predict(X_test_skb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5032292902207474"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = roc_auc_score(y_test2,y_kmeans)\n",
    "scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 16)                3216      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,505\n",
      "Trainable params: 3,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    s = tf.py_function(roc_auc_score,(y_true, y_pred),tf.double)\n",
    "    return s\n",
    "\n",
    "maxfeatures2 = X_train2.shape[1]\n",
    "max_featuresskb = X_train_skb_compl.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(max_featuresskb,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd4e4de2310>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_skb2,y_train2,batch_size=512,epochs=50,verbose=0,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neu = model.predict_proba(X_test_skb2)\n",
    "neus = roc_auc_score(y_test2,neu)\n",
    "neus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STACKING SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "models = [\n",
    "    xgb_final,\n",
    "    cat_final,\n",
    "    ada_final,\n",
    "    rf_final,\n",
    "    LGBMClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [log_loss]\n",
      "mode:         [oof_pred]\n",
      "n_models:     [5]\n",
      "\n",
      "model  0:     [XGBClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.11679690] + [0.00297482]\n",
      "    FULL:     [0.11679698]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "model  1:     [CatBoostClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.12185443] + [0.00266833]\n",
      "    FULL:     [0.12185467]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "model  2:     [AdaBoostClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.45627183] + [0.00659728]\n",
      "    FULL:     [0.45627252]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "model  3:     [RandomForestClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.42956417] + [0.00354176]\n",
      "    FULL:     [0.42956395]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "model  4:     [LGBMClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.14336312] + [0.00833161]\n",
      "    FULL:     [0.14336358]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "Result was saved to [./[2019.11.23].[01.24.10].661032.67a51f.npy]\n"
     ]
    }
   ],
   "source": [
    "from vecstack import stacking\n",
    "\n",
    "S_train, S_test = stacking(models,                                             # list of models\n",
    "                               X_train_skb_compl, y_train, X_test_skb_compl,   # data\n",
    "                               regression=False,                               # classification task (if you need \n",
    "                                                                               #     regression - set to True)\n",
    "                               mode='oof_pred',                                # mode: oof for train set, fit on full \n",
    "                                                                               #     train and predict test set once\n",
    "                               needs_proba=True,                               # predict probabilities (if you need \n",
    "                                                                               #     class labels - set to False) \n",
    "                               save_dir='.',                                   # save result and log in current dir \n",
    "                                                                               #     (to disable saving - set to None)\n",
    "                               n_folds=5,                                      # number of folds\n",
    "                               stratified=True,                                # stratified split for folds\n",
    "                               shuffle=True,                                   # shuffle the data\n",
    "                               random_state=0,                                 # ensure reproducibility\n",
    "                               verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, sub_sample=0.5, subsample=1, verbosity=0)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_of_models = xgb_final\n",
    "model_of_models.fit(S_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_final = pd.Series(sol_final[:,1])\n",
    "resultado_final.index.name=\"USER_ID\" # Renombramos las columnas\n",
    "resultado_final.name=\"SCORE\" # Renombramos las columnas\n",
    "resultado_final.to_csv(\"respuesta_final\", header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
