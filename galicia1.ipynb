{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Kernel with minimal variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['device_data.csv', 'pageviews_complemento.csv', 'sampleSubmission.csv', 'SITE_ID.csv', 'PAGE.csv', 'README.md', 'CONTENT_CATEGORY.csv', 'CONTENT_CATEGORY_BOTTOM.csv', 'pageviews.csv', 'conversiones.csv', 'CONTENT_CATEGORY_TOP.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "np.set_printoptions(threshold=200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../data/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/horacio/.conda/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([\n",
    "       pd.read_csv(\"../data/pageviews.csv\", parse_dates=[\"FEC_EVENT\"]),\n",
    "       pd.read_csv(\"../data/pageviews_complemento.csv\", parse_dates=[\"FEC_EVENT\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_test.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_test = pd.concat(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[0,0:65].sum() # la suma de las frecuencias debe ser 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.FEC_EVENT.dt.month < 10]\n",
    "X_train = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_train.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_train = pd.concat(X_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[0,0:65].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(X_train.columns).intersection(set(X_test.columns)))\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev = pd.read_csv(\"../data/conversiones.csv\")\n",
    "y_train = pd.Series(0, index=X_train.index)\n",
    "idx = set(y_prev[y_prev.mes >= 10].USER_ID.unique()).intersection(set(X_train.index))\n",
    "y_train.loc[list(idx)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "test = SelectKBest(chi2,k=250)\n",
    "fit = test.fit(X_train, y_train)\n",
    "X_train_alt = pd.DataFrame(fit.transform(X_train))\n",
    "X_test_alt = pd.DataFrame(fit.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "fi = []\n",
    "test_probs = []\n",
    "i = 0\n",
    "for train_idx, valid_idx in model_selection.KFold(n_splits=10, shuffle=True).split(X_train):\n",
    "    i += 1\n",
    "    Xt = X_train.iloc[train_idx]\n",
    "    yt = y_train.loc[X_train.index].iloc[train_idx]\n",
    "\n",
    "    Xv = X_train.iloc[valid_idx]\n",
    "    yv = y_train.loc[X_train.index].iloc[valid_idx]\n",
    "\n",
    "    adalearner = AdaBoostClassifier()\n",
    "    adalearner.fit(Xt, yt)\n",
    "    adalearner.predict_proba(Xv)\n",
    "    puntis = roc_auc_score(Xv,yv[1])\n",
    "    \n",
    "    test_probs.append(pd.Series(adalearner.predict_proba(X_test)[:,-1],\n",
    "                            index=X_test.index, name=\"fold_\" + str(i)))\n",
    "    \n",
    "    #learner = LGBMClassifier(n_estimators=10000)\n",
    "    #learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "    #            eval_set=[(Xt, yt), (Xv, yv)])\n",
    "    \n",
    "test_probs.append(pd.Series(adalearner.predict_proba(X_test)[:, -1],\n",
    "                            index=X_test.index))#, name=\"fold_\" + str(i)))\n",
    "fi.append(pd.Series(adalearner.feature_importances_ / adalearner.feature_importances_.sum(), index=X_train.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "test_probs.index.name=\"USER_ID\"\n",
    "test_probs.name=\"SCORE\"\n",
    "test_probs.to_csv(\"respuesta\", header=True, compression=\"zip\")\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati = pd.read_csv(\"respuesta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train set and Test set\n",
    "\n",
    "We split the test set, so we use last three months to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo CONTENT_CATEGORY\n",
      "haciendo CONTENT_CATEGORY_BOTTOM\n",
      "haciendo CONTENT_CATEGORY_TOP\n",
      "haciendo ON_SITE_SEARCH_TERM\n",
      "haciendo PAGE\n",
      "haciendo SITE_ID\n"
     ]
    }
   ],
   "source": [
    "data = data[data.FEC_EVENT.dt.month < 10]\n",
    "X_test2 = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_test2.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_test2 = pd.concat(X_test2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo CONTENT_CATEGORY\n",
      "haciendo CONTENT_CATEGORY_BOTTOM\n",
      "haciendo CONTENT_CATEGORY_TOP\n",
      "haciendo ON_SITE_SEARCH_TERM\n",
      "haciendo PAGE\n",
      "haciendo SITE_ID\n"
     ]
    }
   ],
   "source": [
    "data = data[(data.FEC_EVENT.dt.month < 7)]\n",
    "X_train2 = []\n",
    "for c in data.drop([\"USER_ID\", \"FEC_EVENT\"], axis=1).columns:\n",
    "    print(\"haciendo\", c)\n",
    "    temp = pd.crosstab(data.USER_ID, data[c])\n",
    "    temp.columns = [c + \"_\" + str(v) for v in temp.columns]\n",
    "    X_train2.append(temp.apply(lambda x: x / x.sum(), axis=1))\n",
    "X_train2 = pd.concat(X_train2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev2 = pd.read_csv(\"../data/conversiones.csv\")\n",
    "y_test2 = pd.Series(0, index=X_test2.index)\n",
    "idx = set(y_prev2[y_prev2.mes >= 10].USER_ID.unique()).intersection(set(X_test2.index))\n",
    "y_test2.loc[list(idx)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = pd.Series(0, index=X_train2.index)\n",
    "idx = set(y_prev2[(y_prev2.mes < 10) & (y_prev2.mes > 6)].USER_ID.unique()).intersection(set(X_train2.index))\n",
    "y_train2.loc[list(idx)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1890) (11314,) (11529, 2026) (11529,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape, y_train2.shape, X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(X_train2.columns).intersection(set(X_test2.columns)))\n",
    "X_train2 = X_train2[features]\n",
    "X_test2 = X_test2[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some feature selection\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "test = SelectKBest(chi2,k=200)\n",
    "fit = test.fit(X_train2, y_train2)\n",
    "X_train2 = pd.DataFrame(fit.transform(X_train2))\n",
    "X_test2 = pd.DataFrame(fit.transform(X_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    'criterion' : ['gini','entropy'],\n",
    "    'splitter' : ['best','random'],\n",
    "    'min_samples_split' : [0.2,0.5,0.7,1.,2,3,4,5],\n",
    "    'min_samples_leaf' : [1,3,5],\n",
    "    'max_depth' : [None,1,2,4,6,8,10],\n",
    "    'min_weight_fraction_leaf' : [0.,0.2,0.5],\n",
    "    'max_features' : [None,10,25,50,75,100,150,200,250],\n",
    "    'random_state' : [None,23,47,88],\n",
    "    'max_leaf_nodes' : [None,10,25,50,100,200,500],\n",
    "    'presort' : [False, True],\n",
    "    'class_weight' : [None,'Balanced']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(dtc, params, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "scores = roc_auc_score(y_test2,parciales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train2.shape, X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc2 = DecisionTreeClassifier()\n",
    "dtc2.fit(X_train2, y_train2)\n",
    "parciales = dtc2.predict(X_test2)\n",
    "scores = roc_auc_score(y_test2,parciales)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization through GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "pg = [\n",
    "    {\"splitter\":[\"best\",\"random\"],\n",
    "     \"max_depth\":[1,2,3,4,5,7,10], \n",
    "     \"max_features\":[10,50,100,150,200], \n",
    "     \"max_leaf_nodes\":[10,50,100,150,200]}\n",
    "]\n",
    "\n",
    "opt = GridSearchCV(dtc2, pg, scoring=\"roc_auc\",n_jobs=-1,cv=StratifiedKFold(5))\n",
    "opt.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(opt.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_decision_tree = opt.best_estimator_\n",
    "optimised_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_decision_tree.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = optimised_decision_tree.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = roc_auc_score(y_test2,sol[:,1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth = 4)\n",
    "clf = AdaBoostClassifier(n_estimators = 8)\n",
    "clf.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probab = clf.predict_proba(X_test2)\n",
    "probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = roc_auc_score(y_test2,probab[:,1])\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
